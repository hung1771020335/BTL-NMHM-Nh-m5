{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import classification_report, accuracy_score, f1_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","\n","# ----------------------------------------------------------------------\n","# 0. Chuẩn bị Dữ liệu: Đọc và Hợp nhất\n","# ----------------------------------------------------------------------\n","\n","print(\"--- 0. Chuẩn bị Dữ liệu ---\")\n","\n","# Giả định các file đã được tải lên Colab và có thể đọc trực tiếp\n","try:\n","    df_train = pd.read_csv('Train.csv')\n","    df_test = pd.read_csv('Test.csv')\n","    df_meta = pd.read_csv('Meta.csv')\n","except FileNotFoundError as e:\n","    print(f\"LỖI: Không tìm thấy file. Hãy đảm bảo bạn đã upload các file CSV lên Colab. Chi tiết: {e}\")\n","    exit()\n","\n","# Hợp nhất dữ liệu Train/Test với Meta data\n","# Merge dựa trên ClassId, vì ShapeId, ColorId, SignId là thuộc tính của ClassId\n","df_train = pd.merge(df_train, df_meta[['ClassId', 'ShapeId', 'ColorId', 'SignId']], on='ClassId', how='left')\n","df_test = pd.merge(df_test, df_meta[['ClassId', 'ShapeId', 'ColorId', 'SignId']], on='ClassId', how='left')\n","\n","# Phân tách X và Y\n","X_train_raw = df_train.drop(['ClassId', 'Path'], axis=1)\n","y_train = df_train['ClassId']\n","X_test_raw = df_test.drop(['ClassId', 'Path'], axis=1)\n","y_test = df_test['ClassId']\n","\n","# Dữ liệu thử nghiệm (validation) để huấn luyện Autoencoder\n","X_train_ae, X_val_ae, y_train_ae, y_val_ae = train_test_split(X_train_raw, y_train, test_size=0.2, random_state=42, stratify=y_train)\n","\n","\n","# ----------------------------------------------------------------------\n","# 1. Khám phá và Phân tích Dữ liệu (EDA)\n","# ----------------------------------------------------------------------\n","\n","print(\"\\n--- 1. Khám phá và Phân tích Dữ liệu (EDA) ---\")\n","print(f\"Kích thước tập huấn luyện: {df_train.shape}\")\n","print(f\"Kích thước tập kiểm tra: {df_test.shape}\")\n","print(\"\\nThông tin cấu trúc tập huấn luyện:\")\n","X_train_raw.info()\n","\n","# Phân tích Đặc trưng Mục tiêu (Target Variable)\n","print(\"\\nPhân phối Đặc trưng Mục tiêu (ClassId):\")\n","target_counts = y_train.value_counts().sort_index()\n","print(target_counts.head())\n","print(f\"Số lượng lớp: {len(target_counts)}\")\n","min_class = target_counts.min()\n","max_class = target_counts.max()\n","print(f\"Mất cân bằng lớp: Lớp ít nhất ({min_class} mẫu) vs Lớp nhiều nhất ({max_class} mẫu).\")\n","\n","# Trực quan hóa (chạy trong Colab để hiển thị)\n","# plt.figure(figsize=(12, 5))\n","# sns.countplot(y=y_train, order=y_train.value_counts().index)\n","# plt.title('Phân phối số lượng mẫu theo ClassId (Kiểm tra mất cân bằng lớp)')\n","# plt.show()\n","\n","# Phân tích Đặc trưng Số và Đặc trưng Phân loại\n","numerical_cols = ['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']\n","categorical_cols = ['ShapeId', 'ColorId', 'SignId']\n","\n","# Thống kê mô tả đặc trưng số\n","print(\"\\nThống kê mô tả Đặc trưng Số:\")\n","print(X_train_raw[numerical_cols].describe())\n","\n","# Kiểm tra dữ liệu thiếu (Missing Values)\n","print(\"\\nKiểm tra Dữ liệu Thiếu:\")\n","print(df_train.isnull().sum())\n","# Giả sử không có dữ liệu thiếu đáng kể sau khi merge (chỉ kiểm tra các cột mới)\n","\n","# Phân tích mối quan hệ: Ma trận tương quan (Correlation Matrix)\n","# correlation_matrix = X_train_raw[numerical_cols].corr()\n","# plt.figure(figsize=(8, 6))\n","# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n","# plt.title('Ma trận tương quan giữa các Đặc trưng Số')\n","# plt.show()\n","\n","\n","# ----------------------------------------------------------------------\n","# 2. Tiền xử lý và Kỹ thuật Đặc trưng\n","# ----------------------------------------------------------------------\n","\n","# Xác định lại các cột\n","NUMERICAL_COLS = ['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2', 'Area', 'Roi_Width', 'Roi_Height', 'Roi_Area', 'Aspect_Ratio', 'Roi_Ratio']\n","META_COLS = ['ShapeId', 'ColorId', 'SignId']\n","TARGET_COL = 'ClassId'\n","\n","# 2.1. Feature Engineering (Áp dụng cho cả Luồng A và Luồng B)\n","\n","def create_new_features(df):\n","    \"\"\"Tạo các đặc trưng mới từ bounding box và ROI.\"\"\"\n","    df['Area'] = df['Width'] * df['Height']\n","    df['Roi_Width'] = df['Roi.X2'] - df['Roi.X1']\n","    df['Roi_Height'] = df['Roi.Y2'] - df['Roi.Y1']\n","    df['Roi_Area'] = df['Roi_Width'] * df['Roi_Height']\n","    # Tránh chia cho 0\n","    df['Aspect_Ratio'] = np.where(df['Height'] != 0, df['Width'] / df['Height'], 0)\n","    df['Roi_Ratio'] = np.where(df['Roi_Height'] != 0, df['Roi_Width'] / df['Roi_Height'], 0)\n","    return df\n","\n","X_train_fe = create_new_features(X_train_raw.copy())\n","X_test_fe = create_new_features(X_test_raw.copy())\n","\n","\n","# --- Luồng A: Kỹ thuật Đặc trưng Truyền thống ---\n","\n","# Lý giải lựa chọn:\n","# - Xử lý dữ liệu thiếu: Dùng Mode/Median cho các cột bị thiếu (nếu có, mặc dù đã merge và không có NaN)\n","# - Mã hóa: One-Hot Encoding cho các đặc trưng phân loại (ShapeId, ColorId, SignId) vì chúng là dữ liệu định danh (nominal). SignId được coi là mã danh mục.\n","# - Chuẩn hóa: StandardScaler được chọn vì nó chuẩn hóa dữ liệu xung quanh giá trị 0 với độ lệch chuẩn 1, phù hợp cho nhiều thuật toán, đặc biệt là các mô hình dựa trên gradient (như Logistic Regression).\n","\n","# Khai báo Preprocessor cho Luồng A\n","preprocessor_A = ColumnTransformer(\n","    transformers=[\n","        # 1. Chuẩn hóa/Quy mô hóa Đặc trưng Số: StandardScaler\n","        ('num', StandardScaler(), NUMERICAL_COLS),\n","        # 2. Mã hóa Đặc trưng Phân loại: One-Hot Encoding\n","        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), META_COLS)\n","    ],\n","    remainder='passthrough'\n",")\n","\n","# Áp dụng Preprocessor Luồng A\n","X_train_A = preprocessor_A.fit_transform(X_train_fe)\n","X_test_A = preprocessor_A.transform(X_test_fe)\n","\n","print(\"\\nKích thước bộ đặc trưng Luồng A (Truyền thống):\", X_train_A.shape)\n","\n","\n","# --- Luồng B: Học Đặc trưng bằng Autoencoder ---\n","\n","# 2.2. Chuẩn bị dữ liệu cho Autoencoder\n","# Autoencoder cần input nằm trong khoảng [0, 1] để học tốt hơn, nên dùng MinMaxScaler cho toàn bộ dữ liệu.\n","# Sử dụng bộ tiền xử lý tương tự Luồng A, nhưng dùng MinMaxScaler.\n","\n","preprocessor_B_AE = ColumnTransformer(\n","    transformers=[\n","        ('num', MinMaxScaler(), NUMERICAL_COLS),\n","        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), META_COLS)\n","    ],\n","    remainder='passthrough'\n",")\n","\n","X_train_B_full = preprocessor_B_AE.fit_transform(X_train_fe)\n","X_test_B_full = preprocessor_B_AE.transform(X_test_fe)\n","\n","input_dim = X_train_B_full.shape[1]\n","# Kích thước lớp cổ chai: Chọn giá trị nén (~1/3 đến 1/5 Input Dim), ở đây chọn 10.\n","# Lý giải: Kích thước 10 đảm bảo nén thông tin hiệu quả (giảm chiều dữ liệu từ ~40 về 10) nhưng đủ lớn để không mất mát quá nhiều chi tiết quan trọng.\n","BOTTLENECK_DIM = 10\n","\n","# 2.3. Xây dựng và Huấn luyện Autoencoder\n","def build_autoencoder(input_dim, bottleneck_dim):\n","    # Encoder\n","    input_layer = Input(shape=(input_dim,))\n","    encoder = Dense(input_dim // 2, activation='relu')(input_layer)\n","    encoder = Dense(input_dim // 4, activation='relu')(encoder)\n","    bottleneck = Dense(bottleneck_dim, activation='relu', name='bottleneck')(encoder)\n","\n","    # Decoder\n","    decoder = Dense(input_dim // 4, activation='relu')(bottleneck)\n","    decoder = Dense(input_dim // 2, activation='relu')(decoder)\n","    output_layer = Dense(input_dim, activation='sigmoid')(decoder) # Dùng sigmoid vì input đã được scale về [0, 1]\n","\n","    # Model\n","    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n","    return autoencoder, Model(inputs=input_layer, outputs=bottleneck) # Trả về Encoder riêng\n","\n","# Quá trình huấn luyện:\n","# - Hàm mất mát (Loss): Mean Squared Error (MSE), đo lường sai số tái tạo.\n","# - Thuật toán tối ưu (Optimizer): Adam.\n","# - Số epochs: 50-100 (Chọn 50 để chạy nhanh)\n","# - Kích thước batch: 32\n","\n","autoencoder, encoder = build_autoencoder(input_dim, BOTTLENECK_DIM)\n","autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n","\n","print(\"\\nBắt đầu Huấn luyện Autoencoder (Luồng B)...\")\n","history = autoencoder.fit(\n","    X_train_B_full, X_train_B_full, # X và Y là như nhau (dữ liệu đầu vào)\n","    epochs=50,\n","    batch_size=32,\n","    shuffle=True,\n","    validation_data=(X_test_B_full, X_test_B_full),\n","    verbose=0 # Tắt log để hiển thị gọn gàng\n",")\n","print(\"Huấn luyện Autoencoder hoàn tất. Loss cuối: {:.4f}\".format(history.history['loss'][-1]))\n","\n","# 2.4. Trích xuất Đặc trưng (Feature Extraction)\n","X_train_B = encoder.predict(X_train_B_full)\n","X_test_B = encoder.predict(X_test_B_full)\n","\n","print(\"Kích thước bộ đặc trưng Luồng B (Autoencoder):\", X_train_B.shape)\n","\n","\n","# ----------------------------------------------------------------------\n","# 3. Huấn luyện Mô hình & 4. Đánh giá và Phân tích Kết quả\n","# ----------------------------------------------------------------------\n","\n","# Lựa chọn thuật toán:\n","# 1. Logistic Regression (mô hình tuyến tính)\n","# 2. Random Forest Classifier (mô hình cây/non-linear mạnh mẽ)\n","\n","results = []\n","\n","def evaluate_model(model_name, X_train, y_train, X_test, y_test, feature_flow):\n","    \"\"\"Huấn luyện và đánh giá mô hình, trả về kết quả.\"\"\"\n","    if model_name == 'Logistic Regression':\n","        model = LogisticRegression(max_iter=500, solver='sag', multi_class='multinomial', random_state=42)\n","    elif model_name == 'Random Forest':\n","        model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n","\n","    # Huấn luyện\n","    model.fit(X_train, y_train)\n","\n","    # Dự đoán\n","    y_pred = model.predict(X_test)\n","\n","    # Đánh giá\n","    accuracy = accuracy_score(y_test, y_pred)\n","    f1_macro = f1_score(y_test, y_pred, average='macro')\n","\n","    print(f\"\\nKết quả {model_name} trên {feature_flow}:\")\n","    print(classification_report(y_test, y_pred, zero_division=0))\n","\n","    return {\n","        'Feature_Flow': feature_flow,\n","        'Model': model_name,\n","        'Accuracy': accuracy,\n","        'F1_Macro': f1_macro\n","    }\n","\n","# 3.1. Huấn luyện trên Luồng A (Traditional Features)\n","print(\"\\n\" + \"=\"*50)\n","print(\"HUẤN LUYỆN & ĐÁNH GIÁ (LUỒNG A: TRUYỀN THỐNG)\")\n","results.append(evaluate_model('Logistic Regression', X_train_A, y_train, X_test_A, y_test, 'Luồng A'))\n","results.append(evaluate_model('Random Forest', X_train_A, y_train, X_test_A, y_test, 'Luồng A'))\n","\n","# 3.2. Huấn luyện trên Luồng B (Autoencoder Features)\n","print(\"\\n\" + \"=\"*50)\n","print(\"HUẤN LUYỆN & ĐÁNH GIÁ (LUỒNG B: AUTOENCODER)\")\n","results.append(evaluate_model('Logistic Regression', X_train_B, y_train, X_test_B, y_test, 'Luồng B'))\n","results.append(evaluate_model('Random Forest', X_train_B, y_train, X_test_B, y_test, 'Luồng B'))\n","\n","# 4. Lập bảng so sánh\n","results_df = pd.DataFrame(results)\n","print(\"\\n\" + \"=\"*50)\n","print(\"BẢNG SO SÁNH HIỆU SUẤT TỔNG HỢP\")\n","print(results_df.sort_values(by='Accuracy', ascending=False).to_markdown(index=False, floatfmt=\".4f\"))\n","print(\"=\"*50)\n","\n","\n","# ----------------------------------------------------------------------\n","# 5. So sánh và Kết luận\n","# ----------------------------------------------------------------------\n","\n","best_model = results_df.loc[results_df['Accuracy'].idxmax()]\n","print(\"\\n--- 5. So sánh và Kết luận ---\")\n","\n","print(f\"Mô hình tốt nhất: {best_model['Model']} ({best_model['Feature_Flow']}) với Accuracy = {best_model['Accuracy']:.4f} và F1-Macro = {best_model['F1_Macro']:.4f}\")\n","\n","print(\"\\n--- Phân tích Ưu và Nhược điểm ---\")\n","\n","print(\"Luồng A (Kỹ thuật Đặc trưng Truyền thống):\")\n","print(\"- Ưu điểm: \\n\\t+ Tính diễn giải cao, dễ hiểu (ví dụ: biết Area, Aspect Ratio quan trọng).\\n\\t+ Quá trình tiền xử lý nhanh, không cần huấn luyện mạng nơ-ron.\")\n","print(\"- Nhược điểm:\\n\\t+ Phụ thuộc vào kiến thức chuyên môn (domain knowledge) để tạo đặc trưng tốt.\\n\\t+ Độ dài vector đặc trưng có thể lớn (do One-Hot Encoding).\")\n","\n","print(\"\\nLuồng B (Học Đặc trưng bằng Autoencoder):\")\n","print(f\"- Ưu điểm: \\n\\t+ **Giảm chiều dữ liệu hiệu quả** (từ {input_dim} về {BOTTLENECK_DIM} chiều), giảm nhiễu, chống overfitting.\\n\\t+ Tự động học các mối quan hệ phức tạp trong dữ liệu, không cần kiến thức chuyên môn sâu.\")\n","print(\"- Nhược điểm:\\n\\t+ Tốn thời gian và tài nguyên để huấn luyện Autoencoder.\\n\\t+ Tính diễn giải (interpretability) thấp: khó hiểu ý nghĩa của từng chiều trong không gian đặc trưng mới.\")\n","\n","print(\"\\n--- Kết luận về Hiệu quả ---\")\n","\n","# Dựa trên kết quả giả định (thường Random Forest trên Luồng A/B sẽ cao hơn Logistic Regression):\n","if best_model['Feature_Flow'] == 'Luồng A':\n","    print(\"Luồng A mang lại hiệu quả tốt hơn cho bài toán này.\")\n","    print(\"Giả thuyết: Các đặc trưng thủ công (Area, Aspect Ratio) đã trích xuất đủ thông tin quan trọng một cách rõ ràng. Sự phức tạp của Autoencoder có thể đã nén quá mức hoặc không tìm thấy các mối quan hệ ẩn giá trị hơn các đặc trưng kỹ thuật thủ công đơn giản.\")\n","else:\n","    print(\"Luồng B mang lại hiệu quả tốt hơn cho bài toán này.\")\n","    print(\"Giả thuyết: Autoencoder đã thành công trong việc tạo ra một không gian đặc trưng **cô đọng** và **giàu thông tin** hơn. Bằng cách loại bỏ các thông tin dư thừa và chỉ giữ lại bản chất cốt lõi của dữ liệu (bottleneck layer), nó giúp mô hình học máy (đặc biệt là Random Forest) hoạt động hiệu quả hơn, ngay cả khi với số chiều dữ liệu thấp hơn nhiều so với Luồng A.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1E-tWDciJGA","executionInfo":{"status":"ok","timestamp":1758848821300,"user_tz":-420,"elapsed":411519,"user":{"displayName":"Việt Hưng Nguyễn","userId":"03588200458589178773"}},"outputId":"f3f061ce-5f16-44cb-98bb-92be631df291"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- 0. Chuẩn bị Dữ liệu ---\n","\n","--- 1. Khám phá và Phân tích Dữ liệu (EDA) ---\n","Kích thước tập huấn luyện: (39209, 11)\n","Kích thước tập kiểm tra: (12630, 11)\n","\n","Thông tin cấu trúc tập huấn luyện:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 39209 entries, 0 to 39208\n","Data columns (total 9 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   Width    39209 non-null  int64 \n"," 1   Height   39209 non-null  int64 \n"," 2   Roi.X1   39209 non-null  int64 \n"," 3   Roi.Y1   39209 non-null  int64 \n"," 4   Roi.X2   39209 non-null  int64 \n"," 5   Roi.Y2   39209 non-null  int64 \n"," 6   ShapeId  39209 non-null  int64 \n"," 7   ColorId  39209 non-null  int64 \n"," 8   SignId   38759 non-null  object\n","dtypes: int64(8), object(1)\n","memory usage: 2.7+ MB\n","\n","Phân phối Đặc trưng Mục tiêu (ClassId):\n","ClassId\n","0     210\n","1    2220\n","2    2250\n","3    1410\n","4    1980\n","Name: count, dtype: int64\n","Số lượng lớp: 43\n","Mất cân bằng lớp: Lớp ít nhất (210 mẫu) vs Lớp nhiều nhất (2250 mẫu).\n","\n","Thống kê mô tả Đặc trưng Số:\n","              Width        Height        Roi.X1        Roi.Y1        Roi.X2  \\\n","count  39209.000000  39209.000000  39209.000000  39209.000000  39209.000000   \n","mean      50.835880     50.328930      5.999515      5.962381     45.197302   \n","std       24.306933     23.115423      1.475493      1.385440     23.060157   \n","min       25.000000     25.000000      0.000000      5.000000     20.000000   \n","25%       35.000000     35.000000      5.000000      5.000000     29.000000   \n","50%       43.000000     43.000000      6.000000      6.000000     38.000000   \n","75%       58.000000     58.000000      6.000000      6.000000     53.000000   \n","max      243.000000    225.000000     20.000000     20.000000    223.000000   \n","\n","             Roi.Y2  \n","count  39209.000000  \n","mean      44.728379  \n","std       21.971145  \n","min       20.000000  \n","25%       30.000000  \n","50%       38.000000  \n","75%       52.000000  \n","max      205.000000  \n","\n","Kiểm tra Dữ liệu Thiếu:\n","Width        0\n","Height       0\n","Roi.X1       0\n","Roi.Y1       0\n","Roi.X2       0\n","Roi.Y2       0\n","ClassId      0\n","Path         0\n","ShapeId      0\n","ColorId      0\n","SignId     450\n","dtype: int64\n","\n","Kích thước bộ đặc trưng Luồng A (Truyền thống): (39209, 54)\n","\n","Bắt đầu Huấn luyện Autoencoder (Luồng B)...\n","Huấn luyện Autoencoder hoàn tất. Loss cuối: 0.0014\n","\u001b[1m1226/1226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n","\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n","Kích thước bộ đặc trưng Luồng B (Autoencoder): (39209, 10)\n","\n","==================================================\n","HUẤN LUYỆN & ĐÁNH GIÁ (LUỒNG A: TRUYỀN THỐNG)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Kết quả Logistic Regression trên Luồng A:\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        60\n","           1       0.22      0.45      0.29       720\n","           2       0.17      0.53      0.26       750\n","           3       0.16      0.03      0.06       450\n","           4       0.24      0.01      0.02       660\n","           5       0.26      0.11      0.15       630\n","           6       1.00      1.00      1.00       150\n","           7       0.00      0.00      0.00       450\n","           8       0.00      0.00      0.00       450\n","           9       1.00      1.00      1.00       480\n","          10       1.00      1.00      1.00       660\n","          11       1.00      1.00      1.00       420\n","          12       1.00      1.00      1.00       690\n","          13       1.00      1.00      1.00       720\n","          14       1.00      1.00      1.00       270\n","          15       1.00      1.00      1.00       210\n","          16       1.00      1.00      1.00       150\n","          17       1.00      1.00      1.00       360\n","          18       1.00      1.00      1.00       390\n","          19       1.00      1.00      1.00        60\n","          20       0.60      0.68      0.64        90\n","          21       1.00      1.00      1.00        90\n","          22       0.73      0.66      0.69       120\n","          23       1.00      1.00      1.00       150\n","          24       1.00      1.00      1.00        90\n","          25       1.00      1.00      1.00       480\n","          26       1.00      1.00      1.00       180\n","          27       1.00      1.00      1.00        60\n","          28       1.00      1.00      1.00       150\n","          29       1.00      1.00      1.00        90\n","          30       1.00      1.00      1.00       150\n","          31       1.00      1.00      1.00       270\n","          32       1.00      1.00      1.00        60\n","          33       1.00      1.00      1.00       210\n","          34       1.00      1.00      1.00       120\n","          35       0.82      1.00      0.90       390\n","          36       1.00      1.00      1.00       120\n","          37       1.00      1.00      1.00        60\n","          38       1.00      1.00      1.00       690\n","          39       1.00      1.00      1.00        90\n","          40       1.00      0.04      0.09        90\n","          41       1.00      1.00      1.00        60\n","          42       1.00      1.00      1.00        90\n","\n","    accuracy                           0.72     12630\n","   macro avg       0.82      0.80      0.79     12630\n","weighted avg       0.71      0.72      0.70     12630\n","\n","\n","Kết quả Random Forest trên Luồng A:\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        60\n","           1       0.23      0.20      0.22       720\n","           2       0.19      0.21      0.20       750\n","           3       0.15      0.11      0.13       450\n","           4       0.19      0.24      0.21       660\n","           5       0.17      0.20      0.18       630\n","           6       1.00      1.00      1.00       150\n","           7       0.08      0.06      0.07       450\n","           8       0.13      0.13      0.13       450\n","           9       1.00      1.00      1.00       480\n","          10       1.00      1.00      1.00       660\n","          11       1.00      1.00      1.00       420\n","          12       1.00      1.00      1.00       690\n","          13       1.00      1.00      1.00       720\n","          14       1.00      1.00      1.00       270\n","          15       1.00      1.00      1.00       210\n","          16       1.00      1.00      1.00       150\n","          17       1.00      1.00      1.00       360\n","          18       1.00      1.00      1.00       390\n","          19       1.00      1.00      1.00        60\n","          20       0.53      0.56      0.54        90\n","          21       1.00      1.00      1.00        90\n","          22       0.66      0.63      0.64       120\n","          23       1.00      1.00      1.00       150\n","          24       1.00      1.00      1.00        90\n","          25       1.00      1.00      1.00       480\n","          26       1.00      1.00      1.00       180\n","          27       1.00      1.00      1.00        60\n","          28       1.00      1.00      1.00       150\n","          29       1.00      1.00      1.00        90\n","          30       1.00      1.00      1.00       150\n","          31       1.00      1.00      1.00       270\n","          32       1.00      1.00      1.00        60\n","          33       1.00      1.00      1.00       210\n","          34       1.00      1.00      1.00       120\n","          35       0.82      0.91      0.86       390\n","          36       1.00      1.00      1.00       120\n","          37       1.00      1.00      1.00        60\n","          38       1.00      1.00      1.00       690\n","          39       1.00      1.00      1.00        90\n","          40       0.24      0.13      0.17        90\n","          41       1.00      1.00      1.00        60\n","          42       1.00      1.00      1.00        90\n","\n","    accuracy                           0.71     12630\n","   macro avg       0.80      0.80      0.80     12630\n","weighted avg       0.71      0.71      0.71     12630\n","\n","\n","==================================================\n","HUẤN LUYỆN & ĐÁNH GIÁ (LUỒNG B: AUTOENCODER)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Kết quả Logistic Regression trên Luồng B:\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        60\n","           1       0.21      0.51      0.30       720\n","           2       0.17      0.42      0.24       750\n","           3       0.14      0.03      0.05       450\n","           4       0.15      0.11      0.13       660\n","           5       0.00      0.00      0.00       630\n","           6       1.00      1.00      1.00       150\n","           7       0.00      0.00      0.00       450\n","           8       0.00      0.00      0.00       450\n","           9       1.00      1.00      1.00       480\n","          10       1.00      1.00      1.00       660\n","          11       1.00      1.00      1.00       420\n","          12       1.00      1.00      1.00       690\n","          13       1.00      1.00      1.00       720\n","          14       1.00      1.00      1.00       270\n","          15       1.00      1.00      1.00       210\n","          16       1.00      1.00      1.00       150\n","          17       1.00      1.00      1.00       360\n","          18       1.00      1.00      1.00       390\n","          19       0.78      0.47      0.58        60\n","          20       0.46      0.67      0.55        90\n","          21       1.00      1.00      1.00        90\n","          22       0.69      0.73      0.71       120\n","          23       1.00      1.00      1.00       150\n","          24       1.00      0.98      0.99        90\n","          25       1.00      1.00      1.00       480\n","          26       1.00      1.00      1.00       180\n","          27       0.97      0.63      0.77        60\n","          28       1.00      1.00      1.00       150\n","          29       1.00      1.00      1.00        90\n","          30       1.00      1.00      1.00       150\n","          31       1.00      1.00      1.00       270\n","          32       1.00      1.00      1.00        60\n","          33       1.00      1.00      1.00       210\n","          34       1.00      1.00      1.00       120\n","          35       0.81      1.00      0.90       390\n","          36       1.00      1.00      1.00       120\n","          37       1.00      1.00      1.00        60\n","          38       1.00      1.00      1.00       690\n","          39       1.00      1.00      1.00        90\n","          40       1.00      0.01      0.02        90\n","          41       1.00      1.00      1.00        60\n","          42       1.00      1.00      1.00        90\n","\n","    accuracy                           0.71     12630\n","   macro avg       0.80      0.78      0.77     12630\n","weighted avg       0.69      0.71      0.69     12630\n","\n","\n","Kết quả Random Forest trên Luồng B:\n","              precision    recall  f1-score   support\n","\n","           0       0.04      0.02      0.02        60\n","           1       0.24      0.23      0.23       720\n","           2       0.20      0.21      0.20       750\n","           3       0.16      0.13      0.14       450\n","           4       0.20      0.25      0.22       660\n","           5       0.17      0.19      0.18       630\n","           6       1.00      0.98      0.99       150\n","           7       0.08      0.06      0.07       450\n","           8       0.12      0.12      0.12       450\n","           9       1.00      1.00      1.00       480\n","          10       1.00      1.00      1.00       660\n","          11       1.00      1.00      1.00       420\n","          12       1.00      1.00      1.00       690\n","          13       1.00      1.00      1.00       720\n","          14       1.00      1.00      1.00       270\n","          15       1.00      1.00      1.00       210\n","          16       1.00      1.00      1.00       150\n","          17       1.00      1.00      1.00       360\n","          18       0.99      1.00      1.00       390\n","          19       1.00      0.50      0.67        60\n","          20       0.42      0.53      0.47        90\n","          21       1.00      1.00      1.00        90\n","          22       0.67      0.62      0.64       120\n","          23       0.91      1.00      0.96       150\n","          24       0.74      0.72      0.73        90\n","          25       1.00      1.00      1.00       480\n","          26       1.00      1.00      1.00       180\n","          27       0.64      0.65      0.64        60\n","          28       1.00      1.00      1.00       150\n","          29       1.00      1.00      1.00        90\n","          30       1.00      1.00      1.00       150\n","          31       1.00      1.00      1.00       270\n","          32       0.95      1.00      0.98        60\n","          33       1.00      1.00      1.00       210\n","          34       1.00      1.00      1.00       120\n","          35       0.82      0.90      0.86       390\n","          36       1.00      1.00      1.00       120\n","          37       1.00      1.00      1.00        60\n","          38       1.00      1.00      1.00       690\n","          39       1.00      1.00      1.00        90\n","          40       0.26      0.16      0.19        90\n","          41       1.00      1.00      1.00        60\n","          42       1.00      1.00      1.00        90\n","\n","    accuracy                           0.71     12630\n","   macro avg       0.78      0.77      0.77     12630\n","weighted avg       0.70      0.71      0.70     12630\n","\n","\n","==================================================\n","BẢNG SO SÁNH HIỆU SUẤT TỔNG HỢP\n","| Feature_Flow   | Model               |   Accuracy |   F1_Macro |\n","|:---------------|:--------------------|-----------:|-----------:|\n","| Luồng A        | Logistic Regression |     0.7216 |     0.7929 |\n","| Luồng B        | Logistic Regression |     0.7139 |     0.7728 |\n","| Luồng A        | Random Forest       |     0.7111 |     0.7989 |\n","| Luồng B        | Random Forest       |     0.7065 |     0.7750 |\n","==================================================\n","\n","--- 5. So sánh và Kết luận ---\n","Mô hình tốt nhất: Logistic Regression (Luồng A) với Accuracy = 0.7216 và F1-Macro = 0.7929\n","\n","--- Phân tích Ưu và Nhược điểm ---\n","Luồng A (Kỹ thuật Đặc trưng Truyền thống):\n","- Ưu điểm: \n","\t+ Tính diễn giải cao, dễ hiểu (ví dụ: biết Area, Aspect Ratio quan trọng).\n","\t+ Quá trình tiền xử lý nhanh, không cần huấn luyện mạng nơ-ron.\n","- Nhược điểm:\n","\t+ Phụ thuộc vào kiến thức chuyên môn (domain knowledge) để tạo đặc trưng tốt.\n","\t+ Độ dài vector đặc trưng có thể lớn (do One-Hot Encoding).\n","\n","Luồng B (Học Đặc trưng bằng Autoencoder):\n","- Ưu điểm: \n","\t+ **Giảm chiều dữ liệu hiệu quả** (từ 54 về 10 chiều), giảm nhiễu, chống overfitting.\n","\t+ Tự động học các mối quan hệ phức tạp trong dữ liệu, không cần kiến thức chuyên môn sâu.\n","- Nhược điểm:\n","\t+ Tốn thời gian và tài nguyên để huấn luyện Autoencoder.\n","\t+ Tính diễn giải (interpretability) thấp: khó hiểu ý nghĩa của từng chiều trong không gian đặc trưng mới.\n","\n","--- Kết luận về Hiệu quả ---\n","Luồng A mang lại hiệu quả tốt hơn cho bài toán này.\n","Giả thuyết: Các đặc trưng thủ công (Area, Aspect Ratio) đã trích xuất đủ thông tin quan trọng một cách rõ ràng. Sự phức tạp của Autoencoder có thể đã nén quá mức hoặc không tìm thấy các mối quan hệ ẩn giá trị hơn các đặc trưng kỹ thuật thủ công đơn giản.\n"]}]}]}